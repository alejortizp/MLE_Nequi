{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb2b4ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score, f1_score, fbeta_score, roc_curve, average_precision_score\n",
    "\n",
    "# Importar funciones necesarias desde tu módulo de funciones\n",
    "from NB_funciones import preprocess_data, log_info, log_error, CargarDatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e12e12bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del modelo\n",
    "CONFIG = {\n",
    "    \"data\": {\n",
    "        \"dataset_name\": \"customer_support_twitter_twcs\",\n",
    "        \"text_column\": \"text\",\n",
    "        \"batch_size\": 100  # Tamaño de lote para predicciones\n",
    "    },\n",
    "    \"mlflow\": {\n",
    "        \"experiment_name\": \"experimento_nuevo_final\",\n",
    "        \"model_name\": \"modelo_nuevo\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelo_mlflow():\n",
    "    \"\"\"\n",
    "    Carga la última versión del modelo desde MLflow.\n",
    "\n",
    "    Esta función construye la URI del modelo utilizando la configuración global y \n",
    "    lo recupera mediante `mlflow.sklearn.load_model()`. Si la carga falla, se registra \n",
    "    el error en los logs.\n",
    "\n",
    "    Args:\n",
    "        None (la función utiliza la configuración global `CONFIG` para obtener el nombre del modelo).\n",
    "\n",
    "    Returns:\n",
    "        sklearn model | None: Modelo cargado desde MLflow si la carga es exitosa, `None` en caso de error.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Captura errores en la carga del modelo y los registra en los logs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model_uri = f\"models:/{CONFIG['mlflow']['model_name']}/latest\"\n",
    "        model = mlflow.sklearn.load_model(model_uri)\n",
    "        log_info(f\"Modelo cargado desde {model_uri}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        log_error(f\"Error al cargar el modelo desde MLflow: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc3b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacer_predicciones_por_lotes(model, datos_nuevos, batch_size=100):\n",
    "    \"\"\"\n",
    "    Realiza predicciones en lotes con el modelo cargado.\n",
    "\n",
    "    Esta función divide los datos de entrada en bloques (`batch_size`) y genera predicciones \n",
    "    en cada iteración para optimizar el procesamiento en modelos grandes. Es útil cuando \n",
    "    el conjunto de datos es extenso y no puede procesarse de una sola vez.\n",
    "\n",
    "    Args:\n",
    "        model: Modelo entrenado que se utilizará para generar predicciones.\n",
    "        datos_nuevos (pd.DataFrame): Conjunto de datos sobre el cual se desean obtener predicciones.\n",
    "        batch_size (int, opcional): Tamaño del lote de datos procesados en cada iteración. Por defecto `100`.\n",
    "\n",
    "    Returns:\n",
    "        list | None: Lista con todas las predicciones generadas, `None` en caso de error.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Captura errores en la inferencia y los registra en los logs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        predicciones_totales = []\n",
    "        \n",
    "        for i in range(0, len(datos_nuevos), batch_size):\n",
    "            batch = datos_nuevos.iloc[i:i + batch_size]\n",
    "            predicciones = model.predict(batch)\n",
    "            predicciones_totales.extend(predicciones)\n",
    "        \n",
    "        return predicciones_totales\n",
    "    except Exception as e:\n",
    "        log_error(f\"Error al hacer predicciones por lotes: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b714c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(accuracy, umbral=0.80):\n",
    "    \"\"\"\n",
    "    Evalúa si el modelo cumple con el umbral mínimo de precisión (`accuracy`).\n",
    "\n",
    "    La función compara la precisión obtenida del modelo con un umbral predefinido y \n",
    "    devuelve `True` si la precisión cumple o supera dicho umbral, o `False` en caso contrario.\n",
    "\n",
    "    Args:\n",
    "        accuracy (float): Precisión obtenida del modelo a evaluar.\n",
    "        umbral (float, opcional): Valor mínimo de precisión esperado para aprobar la evaluación. \n",
    "                                  Por defecto es `0.80` (80%).\n",
    "\n",
    "    Returns:\n",
    "        bool: `True` si la precisión del modelo es mayor o igual al umbral, `False` en caso contrario.\n",
    "    \"\"\"\n",
    "    return accuracy >= umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5892a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Ejecuta el flujo de predicción en lotes con monitoreo.\n",
    "\n",
    "    Este pipeline carga el modelo desde MLflow, obtiene nuevos datos, genera predicciones en lotes \n",
    "    y evalúa su rendimiento comparándolo con un umbral mínimo de precisión (`accuracy`).\n",
    "\n",
    "    Returns:\n",
    "        bool: `True` si el modelo cumple con el umbral de precisión, `False` en caso contrario.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Captura errores en cualquier etapa del flujo y los registra en los logs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        log_info(\"Iniciando flujo de predicción en lotes...\")\n",
    "\n",
    "        # Cargar modelo\n",
    "        model = cargar_modelo_mlflow()\n",
    "        if model is None:\n",
    "            log_error(\"No se pudo cargar el modelo. Deteniendo ejecución.\")\n",
    "            return False\n",
    "        \n",
    "        # Cargar datos nuevos\n",
    "        ruta = CargarDatos(CONFIG[\"data\"][\"dataset_name\"])\n",
    "        datos_nuevos = ruta.cargar_csv()\n",
    "        log_info(f\"Datos nuevos cargados con {datos_nuevos.shape[0]} registros.\")\n",
    "\n",
    "        # Asegurar que el target sea int\n",
    "        datos_nuevos['inbound'] = datos_nuevos['inbound'].astype('int')\n",
    "\n",
    "        # Generar predicciones por lotes\n",
    "        predicciones = hacer_predicciones_por_lotes(model, datos_nuevos['text'], CONFIG[\"data\"][\"batch_size\"])\n",
    "        predictions = [round(value) for value in predicciones]\n",
    "        if predicciones is not None:\n",
    "            log_info(f\"Predicciones generadas exitosamente: {predicciones[:10]}\")\n",
    "\n",
    "        # Calcular accuracy\n",
    "        accuracy = accuracy_score(datos_nuevos['inbound'], predictions)\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "        # Evaluar si cumple con el umbral definido\n",
    "        modelo_aprobado = evaluar_modelo(accuracy, umbral=0.80)  # Ajusta el umbral según necesidad\n",
    "        print(f\"¿Modelo cumple con el umbral? {modelo_aprobado}\")\n",
    "\n",
    "        return modelo_aprobado\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_error(f\"Error crítico en el flujo de predicción por lotes: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b09b4013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iniciando flujo de predicción en lotes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Modelo cargado desde models:/modelo_nuevo/latest\n",
      "INFO:root:Archivo /home/alejo/proyectos/MLE_Nequi/datasets/Customer_Support_Twitter/twcs/twcs.csv cargado correctamente.\n",
      "INFO:root:Datos nuevos cargados con 2811774 registros.\n",
      "INFO:root:Predicciones generadas exitosamente: [np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "¿Modelo cumple con el umbral? True\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    resultado = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805fc6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook NB_monitoreo_final.ipynb to script\n",
      "[NbConvertApp] Writing 5967 bytes to NB_monitoreo_final.py\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbconvert --to script NB_monitoreo_final.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
