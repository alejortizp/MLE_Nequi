{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84382c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import unicodedata\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score, f1_score, fbeta_score, roc_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import string \n",
    "import joblib\n",
    "import warnings\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlflow.models.signature import infer_signature\n",
    "import time\n",
    "from tqdm import tqdm  # para barra de progreso\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99effdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del logging\n",
    "logging.basicConfig(\n",
    "    filename=\"errores_entrenamiento.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41bea6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "try:\n",
    "    load_dotenv()\n",
    "    ruta_cst_twcs = os.getenv(\"customer_support_twitter_twcs\")\n",
    "    logging.info(\"Environment variables loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading environment variables: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f35fedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2811774, 7)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "try:\n",
    "    data_cst_twcs = pd.read_csv(ruta_cst_twcs)\n",
    "    print(data_cst_twcs.shape)\n",
    "    logging.info(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    logging.error(f\"File not found: {ruta_cst_twcs}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27b98984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the 'inbound' column to int\n",
    "try:\n",
    "    data_cst_twcs['inbound'] = data_cst_twcs['inbound'].astype('int')\n",
    "    logging.info(\"Data transformed successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error transforming data: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98540112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alejo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/alejo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# load stopwords\n",
    "try:\n",
    "    nltk.download('punkt')\n",
    "    #nltk.download('wordnet')\n",
    "    nltk.download('stopwords')\n",
    "    english_stopwords = stopwords.words('english')\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading stopwords: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eafa001b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1377768,)\n",
      "X_valid:  (590473,)\n",
      "X_test:  (843533,)\n",
      "y_train:  (1377768,)\n",
      "y_valid:  (590473,)\n",
      "y_test:  (843533,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into train, validation and test sets\n",
    "# stratified split to maintain the same proportion of classes in each set\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_cst_twcs['text'], data_cst_twcs['inbound'], test_size=0.3, stratify=data_cst_twcs['inbound'], random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=42)\n",
    "    print('X_train: ', X_train.shape)\n",
    "    print('X_valid: ', X_valid.shape)\n",
    "    print('X_test: ', X_test.shape)\n",
    "    print('y_train: ', y_train.shape)\n",
    "    print('y_valid: ', y_valid.shape)\n",
    "    print('y_test: ', y_test.shape)\n",
    "    logging.info(\"Data split into train, validation and test sets successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error splitting data: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5878cfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento ya existe\n"
     ]
    }
   ],
   "source": [
    "# Set the experiment name\n",
    "try:\n",
    "    mlflow.create_experiment(\"experimento_catboost\")\n",
    "    print(\"Experimento creado\")\n",
    "    logging.info(\"Experiment created successfully.\")\n",
    "except:\n",
    "    mlflow.set_experiment(\"experimento_catboost\")\n",
    "    print(\"Experimento ya existe\")\n",
    "    logging.info(\"Experiment already exists, set to existing experiment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c15fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el modelo más reciente\n",
    "try:\n",
    "    model_name = \"modelo_catboost_prueba\"\n",
    "    model_version = \"latest\"  # Indica que quieres la última versión disponible\n",
    "\n",
    "    loaded_model = mlflow.sklearn.load_model(f\"models:/{model_name}/{model_version}\")\n",
    "    logging.info(f\"Model {model_name} version {model_version} loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading model: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a605751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "try:\n",
    "    pred = loaded_model.predict(X_test)\n",
    "    print(pred)\n",
    "    logging.info(\"Prediction made successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error making prediction: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e852e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realizar_prediccion_batch(modelo, X, tamaño_lote=1000):\n",
    "    \"\"\"\n",
    "    Realiza predicciones en lotes (batches) para evitar problemas de memoria\n",
    "    \"\"\"\n",
    "    try:\n",
    "        inicio = time.time()\n",
    "        n_muestras = X.shape[0]\n",
    "        \n",
    "        # Inicializar array para almacenar resultados\n",
    "        if hasattr(modelo, 'predict_proba'):\n",
    "            # Para modelos que pueden dar probabilidades\n",
    "            primera_pred = modelo.predict_proba(X[:1])\n",
    "            predicciones = np.zeros((n_muestras, primera_pred.shape[1]))\n",
    "            metodo_pred = 'predict_proba'\n",
    "        else:\n",
    "            # Para modelos que solo dan la clase\n",
    "            predicciones = np.zeros(n_muestras)\n",
    "            metodo_pred = 'predict'\n",
    "        \n",
    "        # Procesar por lotes\n",
    "        for i in tqdm(range(0, n_muestras, tamaño_lote)):\n",
    "            fin_lote = min(i + tamaño_lote, n_muestras)\n",
    "            lote = X[i:fin_lote]\n",
    "            \n",
    "            if metodo_pred == 'predict_proba':\n",
    "                predicciones[i:fin_lote] = modelo.predict_proba(lote)\n",
    "            else:\n",
    "                predicciones[i:fin_lote] = modelo.predict(lote)\n",
    "        \n",
    "        fin = time.time()\n",
    "        logging.info(f\"Predicciones completadas en {fin - inicio:.2f} segundos\")\n",
    "        \n",
    "        return predicciones\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error durante la predicción: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fbd4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_resultados(predicciones, datos_original, ruta_salida, incluir_datos_originales=True):\n",
    "    \"\"\"\n",
    "    Guarda los resultados de la predicción en un archivo\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crear DataFrame con las predicciones\n",
    "        if predicciones.ndim > 1:\n",
    "            # Para predicciones de probabilidad con múltiples clases\n",
    "            df_pred = pd.DataFrame(\n",
    "                predicciones, \n",
    "                columns=[f'prob_clase_{i}' for i in range(predicciones.shape[1])]\n",
    "            )\n",
    "            # Agregar la clase con mayor probabilidad\n",
    "            df_pred['prediccion'] = np.argmax(predicciones, axis=1)\n",
    "        else:\n",
    "            # Para predicciones de clase única\n",
    "            df_pred = pd.DataFrame({'prediccion': predicciones})\n",
    "        \n",
    "        # Combinar con datos originales si se solicita\n",
    "        if incluir_datos_originales:\n",
    "            resultado = pd.concat([datos_original.reset_index(drop=True), df_pred], axis=1)\n",
    "        else:\n",
    "            resultado = df_pred\n",
    "        \n",
    "        # Guardar resultados\n",
    "        if ruta_salida.endswith('.csv'):\n",
    "            resultado.to_csv(ruta_salida, index=False)\n",
    "        elif ruta_salida.endswith('.xlsx'):\n",
    "            resultado.to_excel(ruta_salida, index=False)\n",
    "        elif ruta_salida.endswith('.parquet'):\n",
    "            resultado.to_parquet(ruta_salida, index=False)\n",
    "        else:\n",
    "            resultado.to_csv(ruta_salida, index=False)\n",
    "        \n",
    "        logging.info(f\"Resultados guardados en {ruta_salida}\")\n",
    "        return resultado\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al guardar resultados: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a239beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
