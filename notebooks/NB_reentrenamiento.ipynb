{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import unicodedata\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score, f1_score, fbeta_score, roc_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import string \n",
    "import joblib\n",
    "import warnings\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d76677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci贸n del logging\n",
    "logging.basicConfig(\n",
    "    filename=\"errores_entrenamiento.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5168c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "try:\n",
    "    load_dotenv()\n",
    "    ruta_cst_twcs = os.getenv(\"customer_support_twitter_twcs\")\n",
    "    logging.info(\"Environment variables loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading environment variables: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3be8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "try:\n",
    "    data_cst_twcs = pd.read_csv(ruta_cst_twcs)\n",
    "    print(data_cst_twcs.shape)\n",
    "    logging.info(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    logging.error(f\"File not found: {ruta_cst_twcs}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the 'inbound' column to int\n",
    "try:\n",
    "    data_cst_twcs['inbound'] = data_cst_twcs['inbound'].astype('int')\n",
    "    logging.info(\"Data transformed successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error transforming data: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3659f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stopwords\n",
    "try:\n",
    "    nltk.download('punkt')\n",
    "    #nltk.download('wordnet')\n",
    "    nltk.download('stopwords')\n",
    "    english_stopwords = stopwords.words('english')\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading stopwords: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train, validation and test sets\n",
    "# stratified split to maintain the same proportion of classes in each set\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_cst_twcs['text'], data_cst_twcs['inbound'], test_size=0.3, stratify=data_cst_twcs['inbound'], random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=42)\n",
    "    print('X_train: ', X_train.shape)\n",
    "    print('X_valid: ', X_valid.shape)\n",
    "    print('X_test: ', X_test.shape)\n",
    "    print('y_train: ', y_train.shape)\n",
    "    print('y_valid: ', y_valid.shape)\n",
    "    print('y_test: ', y_test.shape)\n",
    "    logging.info(\"Data split into train, validation and test sets successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error splitting data: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2efb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizar el texto con TF-IDF\n",
    "#vectorizer = TfidfVectorizer(stop_words=english_stopwords, max_features=100, lowercase=True, token_pattern=r'\\b\\w+\\b')\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the train, validation and test sets\n",
    "#X_train = vectorizer.fit_transform(X_train)\n",
    "#X_valid = vectorizer.transform(X_valid)\n",
    "#X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ea524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the experiment name\n",
    "try:\n",
    "    mlflow.create_experiment(\"experimento_catboost\")\n",
    "    print(\"Experimento creado\")\n",
    "    logging.info(\"Experiment created successfully.\")\n",
    "except:\n",
    "    mlflow.set_experiment(\"experimento_catboost\")\n",
    "    print(\"Experimento ya existe\")\n",
    "    logging.info(\"Experiment already exists, set to existing experiment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b47d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Iniciando el experimento...\")\n",
    "    with mlflow.start_run():\n",
    "        # Define y entrena el pipeline\n",
    "        catboost_params = {\n",
    "            \"iterations\": 500,\n",
    "            \"depth\": 6,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"verbose\": 100\n",
    "        }\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words=english_stopwords, max_features=100, lowercase=True, token_pattern=r'\\b\\w+\\b')),\n",
    "            ('catboost', CatBoostClassifier(**catboost_params))\n",
    "        ])\n",
    "        pipeline.fit(X_valid, y_valid)\n",
    "\n",
    "        # Inferir signature para input/output\n",
    "        signature = infer_signature(X_valid, y_valid)\n",
    "\n",
    "        # Registra el modelo con un ejemplo de entrada\n",
    "        input_example = np.array(X_train[:1])  # Toma una muestra como ejemplo de entrada\n",
    "        mlflow.sklearn.log_model(pipeline, \"modelo_catboost\", input_example=input_example, signature=signature, registered_model_name=\"modelo_catboost_prueba\")\n",
    "\n",
    "        # Registra las m茅tricas\n",
    "        accuracy = pipeline.score(X_test, y_test)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Registra los hiperpar谩metros del modelo\n",
    "        mlflow.log_params(catboost_params)\n",
    "\n",
    "        print(f\"Modelo registrado con precisi贸n: {accuracy}\")\n",
    "        logging.info(f\"Modelo registrado con precisi贸n: {accuracy}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during MLflow run: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5f8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "488eff33",
   "metadata": {},
   "source": [
    "# MLOps - Proceso de Reentrenamiento y Comparaci贸n de Modelos\n",
    "\n",
    "Este notebook implementa un proceso MLOps para:\n",
    "1. Entrenar un nuevo modelo (challenger)\n",
    "2. Recuperar el modelo campe贸n actual de MLflow (champion)\n",
    "3. Comparar ambos modelos usando m茅tricas definidas\n",
    "4. Registrar como nuevo campe贸n el que tenga mejor desempe帽o\n",
    "5. Documentar toda la experimentaci贸n en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e445be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "    \n",
    "import unicodedata\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score, f1_score, fbeta_score, roc_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import string \n",
    "import joblib\n",
    "import warnings\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlflow.models.signature import infer_signature\n",
    "from datetime import datetime\n",
    "    \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b96135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci贸n del logging\n",
    "logging.basicConfig(\n",
    "    filename=f'reentrenamiento_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log',\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee9f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci贸n para registrar mensajes tanto en log como en consola\n",
    "def log_info(message):\n",
    "    print(message)\n",
    "    logging.info(message)\n",
    "        \n",
    "def log_error(message):\n",
    "    print(f'ERROR: {message}')\n",
    "    logging.error(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c36b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables de entorno cargadas correctamente.\n",
      "Variables de entorno cargadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Cargar variables de entorno\n",
    "try:\n",
    "    load_dotenv()\n",
    "    ruta_cst_twcs = os.getenv('customer_support_twitter_twcs')\n",
    "    # Configurar nombre del modelo campe贸n y experimento\n",
    "    CHAMPION_MODEL_NAME = os.getenv('CHAMPION_MODEL_NAME', 'modelo_catboost_champion')\n",
    "    EXPERIMENT_NAME = os.getenv('EXPERIMENT_NAME', 'experimento_catboost')\n",
    "    # Configurar umbral para considerar un modelo mejor\n",
    "    IMPROVEMENT_THRESHOLD = float(os.getenv('IMPROVEMENT_THRESHOLD', '0.01'))  # 1% de mejora por defecto\n",
    "    # M茅trica principal para comparaci贸n\n",
    "    PRIMARY_METRIC = os.getenv('PRIMARY_METRIC', 'f1')\n",
    "    print('Variables de entorno cargadas correctamente.')\n",
    "    log_info('Variables de entorno cargadas correctamente.')\n",
    "except Exception as e:\n",
    "    print(f'Error al cargar variables de entorno: {e}')\n",
    "    log_error(f'Error al cargar variables de entorno: {e}')\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f49657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset: (2811774, 7)\n",
      "Datos cargados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos\n",
    "try:\n",
    "    data_cst_twcs = pd.read_csv(ruta_cst_twcs)\n",
    "    print(f'Dimensiones del dataset: {data_cst_twcs.shape}')\n",
    "    log_info('Datos cargados correctamente.')\n",
    "except FileNotFoundError as e:\n",
    "    log_error(f'Archivo no encontrado: {ruta_cst_twcs}')\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e71605b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos transformados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Transformar la columna 'inbound' a int\n",
    "try:\n",
    "    data_cst_twcs['inbound'] = data_cst_twcs['inbound'].astype('int')\n",
    "    log_info('Datos transformados correctamente.')\n",
    "except Exception as e:\n",
    "    log_error(f'Error al transformar datos: {e}')\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb3d955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursos NLP cargados correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alejo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/alejo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cargar recursos NLP\n",
    "try:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    english_stopwords = stopwords.words('english')\n",
    "    sentence_tokenizer = nltk.tokenize.punkt.PunktSentenceTokenizer()\n",
    "    log_info('Recursos NLP cargados correctamente.')\n",
    "except Exception as e:\n",
    "    log_error(f'Error al cargar stopwords: {e}')\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39984a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          @115712 I understand. I would like to assist y...\n",
       "1              @sprintcare and how do you propose we do that\n",
       "2          @sprintcare I have sent several private messag...\n",
       "3          @115712 Please send us a Private Message so th...\n",
       "4                                         @sprintcare I did.\n",
       "                                 ...                        \n",
       "2811769    @823869 Hey, we'd be happy to look into this f...\n",
       "2811770    @115714 wtf!? Ive been having really shitty s...\n",
       "2811771    @143549 @sprintcare You have to go to https://...\n",
       "2811772    @823870 Sounds delicious, Sarah!  https://t.c...\n",
       "2811773    @AldiUK  warm sloe gin mince pies with ice cre...\n",
       "Name: text, Length: 2811774, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cst_twcs['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee37c154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [@115712 I understand., I would like to assist...\n",
       "1            [@sprintcare and how do you propose we do that]\n",
       "2          [@sprintcare I have sent several private messa...\n",
       "3          [@115712 Please send us a Private Message so t...\n",
       "4                                       [@sprintcare I did.]\n",
       "                                 ...                        \n",
       "2811769    [@823869 Hey, we'd be happy to look into this ...\n",
       "2811770    [@115714 wtf!?, Ive been having really shitty...\n",
       "2811771    [@143549 @sprintcare You have to go to https:/...\n",
       "2811772    [@823870 Sounds delicious, Sarah!,  https://t...\n",
       "2811773    [@AldiUK  warm sloe gin mince pies with ice cr...\n",
       "Name: tokenized_sentences, Length: 2811774, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar la tokenizaci贸n de oraciones a cada fila\n",
    "#data_cst_twcs['tokenized_sentences'] = data_cst_twcs['text'].apply(sentence_tokenizer.tokenize)\n",
    "#data_cst_twcs['tokenized_sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72fea96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1377768,)\n",
      "X_valid:  (590473,)\n",
      "X_test:  (843533,)\n",
      "y_train:  (1377768,)\n",
      "y_valid:  (590473,)\n",
      "y_test:  (843533,)\n",
      "Datos divididos en conjuntos de entrenamiento, validaci贸n y prueba correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento, validaci贸n y prueba\n",
    "# Divisi贸n estratificada para mantener la misma proporci贸n de clases en cada conjunto\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_cst_twcs['text'], data_cst_twcs['inbound'], \n",
    "                                                        test_size=0.3, stratify=data_cst_twcs['inbound'], \n",
    "                                                        random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, \n",
    "                                                        test_size=0.3, stratify=y_train, \n",
    "                                                        random_state=42)\n",
    "    print('X_train: ', X_train.shape)\n",
    "    print('X_valid: ', X_valid.shape)\n",
    "    print('X_test: ', X_test.shape)\n",
    "    print('y_train: ', y_train.shape)\n",
    "    print('y_valid: ', y_valid.shape)\n",
    "    print('y_test: ', y_test.shape)\n",
    "    log_info('Datos divididos en conjuntos de entrenamiento, validaci贸n y prueba correctamente.')\n",
    "except Exception as e:\n",
    "    log_error(f'Error al dividir los datos: {e}')\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c0a93b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento ya existe\n"
     ]
    }
   ],
   "source": [
    "# Set the experiment name\n",
    "try:\n",
    "    mlflow.create_experiment(\"experimento_catboost\")\n",
    "    print(\"Experimento creado\")\n",
    "    logging.info(\"Experiment created successfully.\")\n",
    "except:\n",
    "    mlflow.set_experiment(\"experimento_catboost\")\n",
    "    print(\"Experimento ya existe\")\n",
    "    logging.info(\"Experiment already exists, set to existing experiment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee174f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando el experimento...\n",
      "0:\tlearn: 0.6316539\ttotal: 2.51s\tremaining: 20m 52s\n",
      "100:\tlearn: 0.3638261\ttotal: 26.8s\tremaining: 1m 45s\n",
      "200:\tlearn: 0.3455131\ttotal: 51s\tremaining: 1m 15s\n",
      "300:\tlearn: 0.3375544\ttotal: 1m 14s\tremaining: 49s\n",
      "400:\tlearn: 0.3330456\ttotal: 1m 37s\tremaining: 24.2s\n",
      "499:\tlearn: 0.3297846\ttotal: 2m 1s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'modelo_catboost_prueba' already exists. Creating a new version of this model...\n",
      "Created version '5' of model 'modelo_catboost_prueba'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo registrado con precisi贸n: 0.8513466574514571\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Iniciando el experimento...\")\n",
    "    with mlflow.start_run():\n",
    "        # Define y entrena el pipeline\n",
    "        catboost_params = {\n",
    "            \"iterations\": 500,\n",
    "            \"depth\": 6,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"verbose\": 100\n",
    "        }\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words=english_stopwords, max_features=100, lowercase=True, token_pattern=r'\\b\\w+\\b')),\n",
    "            ('catboost', CatBoostClassifier(**catboost_params))\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Inferir signature para input/output\n",
    "        signature = infer_signature(X_train, y_train)\n",
    "\n",
    "        # Registra el modelo con un ejemplo de entrada\n",
    "        input_example = np.array(X_train[:1])  # Toma una muestra como ejemplo de entrada\n",
    "        mlflow.sklearn.log_model(pipeline, \"modelo_catboost\", input_example=input_example, signature=signature, registered_model_name=\"modelo_catboost_prueba\")\n",
    "\n",
    "        # Registra las m茅tricas\n",
    "        accuracy = pipeline.score(X_test, y_test)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Registra los hiperpar谩metros del modelo\n",
    "        mlflow.log_params(catboost_params)\n",
    "\n",
    "        print(f\"Modelo registrado con precisi贸n: {accuracy}\")\n",
    "        logging.info(f\"Modelo registrado con precisi贸n: {accuracy}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during MLflow run: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220013b9",
   "metadata": {},
   "source": [
    "## Implementaci贸n del Flujo MLOps\n",
    "    \n",
    "A continuaci贸n, implementamos las funciones para:\n",
    "1. Recuperar el modelo campe贸n actual\n",
    "2. Entrenar un nuevo modelo\n",
    "3. Evaluar y comparar ambos modelos\n",
    "4. Promover el mejor modelo como nuevo campe贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e373674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, model_name='modelo'):\n",
    "    '''Eval煤a un modelo y devuelve un diccionario con m煤ltiples m茅tricas.'''\n",
    "    try:\n",
    "        # Predicciones\n",
    "        y_pred = model.predict(X)\n",
    "        y_pred_proba = model.predict_proba(X)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "            \n",
    "        # M茅tricas b谩sicas\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y, y_pred),\n",
    "            'precision': precision_score(y, y_pred),\n",
    "            'recall': recall_score(y, y_pred),\n",
    "            'f1': f1_score(y, y_pred),\n",
    "        }\n",
    "            \n",
    "        # M茅tricas avanzadas si hay probabilidades\n",
    "        if y_pred_proba is not None:\n",
    "            metrics['roc_auc'] = roc_auc_score(y, y_pred_proba)\n",
    "            metrics['avg_precision'] = average_precision_score(y, y_pred_proba)\n",
    "            \n",
    "        # Reporte de clasificaci贸n\n",
    "        report = classification_report(y, y_pred, output_dict=True)\n",
    "            \n",
    "        log_info(f'Evaluaci贸n de {model_name}:')\n",
    "        for metric, value in metrics.items():\n",
    "            log_info(f'- {metric}: {value:.4f}')\n",
    "                \n",
    "        return metrics, report\n",
    "    except Exception as e:\n",
    "        log_error(f'Error al evaluar el modelo {model_name}: {e}')\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c91d1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model, X, y, title='Matriz de Confusi贸n'):\n",
    "    '''Grafica la matriz de confusi贸n para un modelo.'''\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ConfusionMatrixDisplay.from_estimator(model, X, y, ax=ax)\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    except Exception as e:\n",
    "        log_error(f'Error al graficar matriz de confusi贸n: {e}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3998367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(model, X, y, model_name='Modelo'):\n",
    "    '''Grafica la curva ROC para un modelo.'''\n",
    "    try:\n",
    "        if not hasattr(model, 'predict_proba'):\n",
    "            log_info(f'El modelo {model_name} no soporta predict_proba, no se puede graficar ROC.')\n",
    "            return None\n",
    "                \n",
    "        y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.4f})')\n",
    "        ax.plot([0, 1], [0, 1], 'k--')\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title('Curva ROC')\n",
    "        ax.legend(loc='lower right')\n",
    "        return fig\n",
    "    except Exception as e:\n",
    "        log_error(f'Error al graficar curva ROC: {e}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21339c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_champion_model():\n",
    "    '''Recupera el modelo campe贸n actual desde MLflow.'''\n",
    "    try:\n",
    "        client = mlflow.tracking.MlflowClient()\n",
    "            \n",
    "        # Buscar la 煤ltima versi贸n del modelo campe贸n\n",
    "        try:\n",
    "            latest_version = client.get_latest_versions(CHAMPION_MODEL_NAME, stages=['Production'])\n",
    "            if not latest_version:\n",
    "                log_info(f'No se encontr贸 un modelo {CHAMPION_MODEL_NAME} en producci贸n. Buscando en staging...')\n",
    "                latest_version = client.get_latest_versions(CHAMPION_MODEL_NAME, stages=['Staging'])\n",
    "                    \n",
    "            if not latest_version:\n",
    "                log_info(f'No se encontr贸 un modelo {CHAMPION_MODEL_NAME} en staging. Buscando la versi贸n m谩s reciente...')\n",
    "                latest_version = client.get_latest_versions(CHAMPION_MODEL_NAME)\n",
    "                    \n",
    "            if latest_version:\n",
    "                model_uri = f'models:/{CHAMPION_MODEL_NAME}/{latest_version[0].version}'\n",
    "                champion_model = mlflow.sklearn.load_model(model_uri)\n",
    "                log_info(f'Modelo campe贸n cargado: {CHAMPION_MODEL_NAME} version {latest_version[0].version}')\n",
    "                return champion_model, latest_version[0].run_id\n",
    "            else:\n",
    "                log_info(f'No se encontr贸 ning煤n modelo registrado con el nombre {CHAMPION_MODEL_NAME}')\n",
    "                return None, None\n",
    "        except Exception as e:\n",
    "            log_error(f'No se pudo obtener la 煤ltima versi贸n del modelo: {e}')\n",
    "            return None, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_error(f'Error al recuperar el modelo campe贸n: {e}')\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ec34372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_challenger_model(model, metrics, X_train, y_train, is_champion=False):\n",
    "    '''Registra un modelo desafiante en MLflow.'''\n",
    "    try:\n",
    "        # Inferir firma para input/output\n",
    "        signature = infer_signature(X_train, y_train)\n",
    "            \n",
    "        # Registrar el modelo con un ejemplo de entrada\n",
    "        input_example = np.array(X_train[:1])\n",
    "            \n",
    "        # Nombre del modelo y etapa\n",
    "        model_name = CHAMPION_MODEL_NAME if is_champion else f'{CHAMPION_MODEL_NAME}_challenger'\n",
    "        stage = 'Production' if is_champion else 'Staging'\n",
    "            \n",
    "        # Registrar modelo\n",
    "        mlflow.sklearn.log_model(\n",
    "            model, \n",
    "            'model', \n",
    "            input_example=input_example, \n",
    "            signature=signature, \n",
    "            registered_model_name=model_name\n",
    "        )\n",
    "            \n",
    "        # Registrar m茅tricas\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            mlflow.log_metric(metric_name, metric_value)\n",
    "                \n",
    "        # Si es el campe贸n, mover a producci贸n\n",
    "        if is_champion:\n",
    "            client = mlflow.tracking.MlflowClient()\n",
    "            latest_version = client.get_latest_versions(model_name)[0].version\n",
    "            client.transition_model_version_stage(\n",
    "                name=model_name,\n",
    "                version=latest_version,\n",
    "                stage=stage\n",
    "            )\n",
    "            log_info(f'Modelo {model_name} v{latest_version} promocionado a {stage}')\n",
    "            \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        log_error(f'Error al registrar el modelo: {e}')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "630442ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_challenger_model(X_train, y_train, X_valid=None, y_valid=None, hyperparams=None):\n",
    "    '''Entrena un nuevo modelo desafiante.'''\n",
    "    try:\n",
    "        # Par谩metros por defecto si no se especifican\n",
    "        if hyperparams is None:\n",
    "            hyperparams = {\n",
    "                'iterations': 500,\n",
    "                'depth': 6,\n",
    "                'learning_rate': 0.1,\n",
    "                'verbose': 100,\n",
    "                'max_features': 100\n",
    "            }\n",
    "            \n",
    "        # Extraer par谩metros espec铆ficos de vectorizador y modelo\n",
    "        max_features = hyperparams.pop('max_features', 100)\n",
    "            \n",
    "        log_info(f'Entrenando modelo desafiante con par谩metros: {hyperparams}')\n",
    "            \n",
    "        # Crear pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words=english_stopwords, max_features=max_features, lowercase=True, token_pattern=r'\\b\\w+\\b')),              \n",
    "            ('catboost', CatBoostClassifier(**hyperparams))\n",
    "        ])\n",
    "            \n",
    "        # Entrenar modelo\n",
    "        if X_valid is not None and y_valid is not None:\n",
    "            # Usar conjunto de validaci贸n para early stopping\n",
    "            pipeline.fit(X_train, y_train, catboost__eval_set=[(X_valid, y_valid)])\n",
    "        else:\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            \n",
    "        log_info('Modelo desafiante entrenado correctamente')\n",
    "        return pipeline\n",
    "    except Exception as e:\n",
    "        log_error(f'Error al entrenar modelo desafiante: {e}')\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "591a7a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(X_train, y_train, X_valid, y_valid, max_evals=10):\n",
    "    '''Optimiza hiperpar谩metros usando Hyperopt.'''\n",
    "    try:\n",
    "        log_info('Iniciando optimizaci贸n de hiperpar谩metros...')\n",
    "            \n",
    "        # Definir espacio de b煤squeda\n",
    "        space = {\n",
    "            'max_features': hp.choice('max_features', [50, 100, 200, 300]),\n",
    "            'iterations': hp.choice('iterations', [300, 500, 700]),\n",
    "            'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.3)),\n",
    "            'depth': hp.choice('depth', [4, 6, 8, 10]),\n",
    "            'l2_leaf_reg': hp.loguniform('l2_leaf_reg', np.log(1), np.log(10)),\n",
    "            'verbose': 0\n",
    "        }\n",
    "            \n",
    "        # Funci贸n objetivo para minimizar\n",
    "        def objective(params):\n",
    "            # Extraer max_features para TfidfVectorizer\n",
    "            max_features = params.pop('max_features', 100)\n",
    "                \n",
    "            # Crear y entrenar pipeline\n",
    "            pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=english_stopwords, max_features=max_features, \n",
    "                                            lowercase=True, token_pattern=r'\\b\\w+\\b')),\n",
    "                ('catboost', CatBoostClassifier(**params))\n",
    "            ])\n",
    "                \n",
    "            try:\n",
    "                pipeline.fit(X_train, y_train, catboost__eval_set=[(X_valid, y_valid)])\n",
    "                    \n",
    "                # Evaluar en conjunto de validaci贸n\n",
    "                y_pred = pipeline.predict(X_valid)\n",
    "                f1 = f1_score(y_valid, y_pred)\n",
    "                    \n",
    "                # Reintegrar max_features al diccionario de par谩metros\n",
    "                params['max_features'] = max_features\n",
    "                    \n",
    "                return {'loss': -f1, 'status': STATUS_OK, 'params': params}\n",
    "            except Exception as e:\n",
    "                log_error(f'Error en evaluaci贸n de hiperpar谩metros: {e}')\n",
    "                return {'loss': 0, 'status': STATUS_OK, 'params': params}\n",
    "            \n",
    "        # Ejecutar optimizaci贸n\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=max_evals, trials=trials)\n",
    "            \n",
    "        # Obtener mejores par谩metros\n",
    "        best_params = trials.results[np.argmin([r['loss'] for r in trials.results])]['params']\n",
    "            \n",
    "        log_info(f'Mejores hiperpar谩metros encontrados: {best_params}')\n",
    "        return best_params\n",
    "    except Exception as e:\n",
    "        log_error(f'Error en optimizaci贸n de hiperpar谩metros: {e}')\n",
    "        # Devolver par谩metros por defecto en caso de error\n",
    "        return {\n",
    "            'iterations': 500,\n",
    "            'depth': 6,\n",
    "            'learning_rate': 0.1,\n",
    "            'verbose': 100,\n",
    "            'max_features': 100\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fcc78ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(champion_metrics, challenger_metrics, primary_metric=PRIMARY_METRIC, threshold=IMPROVEMENT_THRESHOLD):\n",
    "    '''Compara los modelos y determina si el desafiante debe convertirse en el nuevo campe贸n.'''\n",
    "    try:\n",
    "        if champion_metrics is None:\n",
    "            log_info('No hay modelo campe贸n para comparar. El desafiante se convierte en campe贸n por defecto.')\n",
    "            return True, {}, {'champion': None, 'challenger': challenger_metrics[primary_metric]}\n",
    "            \n",
    "        # Comparar m茅tricas primarias\n",
    "        champion_score = champion_metrics[primary_metric]\n",
    "        challenger_score = challenger_metrics[primary_metric]\n",
    "            \n",
    "        improvement = challenger_score - champion_score\n",
    "        percent_improvement = (improvement / champion_score) * 100 if champion_score > 0 else float('inf')\n",
    "            \n",
    "        comparison = {\n",
    "            'champion': champion_score,\n",
    "            'challenger': challenger_score,\n",
    "            'absolute_diff': improvement,\n",
    "            'percent_diff': percent_improvement\n",
    "        }\n",
    "            \n",
    "        # Comparar todas las m茅tricas disponibles\n",
    "        all_metrics = {}\n",
    "        for metric in set(champion_metrics.keys()).union(challenger_metrics.keys()):\n",
    "            if metric in champion_metrics and metric in challenger_metrics:\n",
    "                champion_val = champion_metrics[metric]\n",
    "                challenger_val = challenger_metrics[metric]\n",
    "                diff = challenger_val - champion_val\n",
    "                perc_diff = (diff / champion_val) * 100 if champion_val > 0 else float('inf')\n",
    "                    \n",
    "                all_metrics[metric] = {\n",
    "                    'champion': champion_val,\n",
    "                    'challenger': challenger_val,\n",
    "                    'absolute_diff': diff,\n",
    "                    'percent_diff': perc_diff\n",
    "                }\n",
    "            \n",
    "        # Determinar si el desafiante es mejor\n",
    "        is_better = improvement > threshold\n",
    "            \n",
    "        if is_better:\n",
    "            log_info(f'El modelo desafiante es mejor en {primary_metric}: {challenger_score:.4f} vs {champion_score:.4f} ')\n",
    "            log_info(f'Mejora absoluta: {improvement:.4f}, Mejora porcentual: {percent_improvement:.2f}%')\n",
    "        else:\n",
    "            log_info(f'El modelo desafiante NO supera al campe贸n en {primary_metric}: {challenger_score:.4f} vs {champion_score:.4f}')\n",
    "            log_info(f'Diferencia absoluta: {improvement:.4f}, Diferencia porcentual: {percent_improvement:.2f}%')\n",
    "                \n",
    "        return is_better, all_metrics, comparison\n",
    "    except Exception as e:\n",
    "        log_error(f'Error al comparar modelos: {e}')\n",
    "        return False, {}, {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f88d8f",
   "metadata": {},
   "source": [
    "## Flujo Principal MLOps\n",
    "    \n",
    "A continuaci贸n implementamos el flujo completo del proceso MLOps con los siguientes pasos:\n",
    "1. Configurar MLflow\n",
    "2. Obtener el modelo campe贸n actual\n",
    "3. Optimizar hiperpar谩metros para el modelo desafiante\n",
    "4. Entrenar el modelo desafiante\n",
    "5. Evaluar ambos modelos\n",
    "6. Comparar modelos y seleccionar el mejor\n",
    "7. Registrar el nuevo campe贸n si corresponde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a34664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento \"experimento_catboost\" ya existe, usando experimento existente\n"
     ]
    }
   ],
   "source": [
    "# Configurar MLflow\n",
    "try:\n",
    "    # Crear experimento si no existe\n",
    "    try:\n",
    "        mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "        log_info(f'Experimento \"{EXPERIMENT_NAME}\" creado correctamente')\n",
    "    except:\n",
    "        mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "        log_info(f'Experimento \"{EXPERIMENT_NAME}\" ya existe, usando experimento existente')\n",
    "except Exception as e:\n",
    "    log_error(f'Error al configurar MLflow: {e}')\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bef3e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO PROCESO DE REENTRENAMIENTO MLOPS ===\n",
      "1. Obteniendo modelo campe贸n...\n",
      "ERROR: No se pudo obtener la 煤ltima versi贸n del modelo: Registered Model with name=modelo_catboost_champion not found\n",
      "No se encontr贸 modelo campe贸n existente\n",
      "2. Optimizando hiperpar谩metros para modelo desafiante...\n",
      "Iniciando optimizaci贸n de hiperpar谩metros...\n",
      "ERROR: Error en evaluaci贸n de hiperpar谩metros: 0      \n",
      "ERROR: Error en evaluaci贸n de hiperpar谩metros: 0                 \n",
      "ERROR: Error en evaluaci贸n de hiperpar谩metros: 0                 \n",
      "ERROR: Error en evaluaci贸n de hiperpar谩metros: 0                 \n",
      "ERROR: Error en evaluaci贸n de hiperpar谩metros: 0                 \n",
      "ERROR: Error en evaluaci贸n de hiperpar谩metros: 0                 \n",
      "ERROR: Error en evaluaci贸n de hiperpar谩metros: 0                 \n",
      "ERROR: Error en evaluaci贸n de hiperpar谩metros: 0                 \n",
      "ERROR: Error en evaluaci贸n de hiperpar谩metros: 0                 \n",
      "ERROR: Error en evaluaci贸n de hiperpar谩metros: 0                 \n",
      "100%|| 10/10 [03:53<00:00, 23.31s/trial, best loss: 0.0]\n",
      "Mejores hiperpar谩metros encontrados: {'depth': 6, 'iterations': 500, 'l2_leaf_reg': 6.210334752527742, 'learning_rate': 0.12145177637340847, 'verbose': 0}\n",
      "3. Entrenando modelo desafiante...\n",
      "Entrenando modelo desafiante con par谩metros: {'depth': 6, 'iterations': 500, 'l2_leaf_reg': 6.210334752527742, 'learning_rate': 0.12145177637340847, 'verbose': 0}\n",
      "ERROR: Error al entrenar modelo desafiante: 0\n",
      "ERROR: Error en flujo MLOps: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/MLE_Nequi/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     89\u001b[39m     log_error(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mError en flujo MLOps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# 3. Entrenar modelo desafiante\u001b[39;00m\n\u001b[32m     36\u001b[39m log_info(\u001b[33m'\u001b[39m\u001b[33m3. Entrenando modelo desafiante...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m challenger_model = \u001b[43mtrain_challenger_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# 4. Evaluar ambos modelos en conjunto de prueba\u001b[39;00m\n\u001b[32m     40\u001b[39m log_info(\u001b[33m'\u001b[39m\u001b[33m4. Evaluando modelos en conjunto de prueba...\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mtrain_challenger_model\u001b[39m\u001b[34m(X_train, y_train, X_valid, y_valid, hyperparams)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     35\u001b[39m     log_error(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mError al entrenar modelo desafiante: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtrain_challenger_model\u001b[39m\u001b[34m(X_train, y_train, X_valid, y_valid, hyperparams)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Entrenar modelo\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X_valid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y_valid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# Usar conjunto de validaci贸n para early stopping\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatboost__eval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     30\u001b[39m     pipeline.fit(X_train, y_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/MLE_Nequi/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/MLE_Nequi/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:662\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    657\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    658\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    659\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    660\u001b[39m             all_params=params,\n\u001b[32m    661\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/MLE_Nequi/.venv/lib/python3.12/site-packages/catboost/core.py:5245\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5243\u001b[39m     CatBoostClassifier._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5245\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5246\u001b[39m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5247\u001b[39m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/MLE_Nequi/.venv/lib/python3.12/site-packages/catboost/core.py:2395\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2392\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, PATH_TYPES + (Pool,)):\n\u001b[32m   2393\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[33m\"\u001b[39m\u001b[33my may be None only when X is an instance of catboost.Pool or string\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2395\u001b[39m train_params = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_train_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2398\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2399\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2401\u001b[39m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2402\u001b[39m \u001b[43m    \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m   2404\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2405\u001b[39m params = train_params[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2406\u001b[39m train_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mtrain_pool\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/MLE_Nequi/.venv/lib/python3.12/site-packages/catboost/core.py:2348\u001b[39m, in \u001b[36mCatBoost._prepare_train_params\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[39m\n\u001b[32m   2345\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m eval_set[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2346\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33meval_set\u001b[39m\u001b[33m'\u001b[39m\u001b[33m tuple contains at least one None value\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2347\u001b[39m eval_sets.append(\n\u001b[32m-> \u001b[39m\u001b[32m2348\u001b[39m     \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2349\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2350\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_cat_feature_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_text_feature_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2353\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_embedding_feature_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2354\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2355\u001b[39m )\n\u001b[32m   2357\u001b[39m eval_total_row_count += eval_sets[-\u001b[32m1\u001b[39m].num_row()\n\u001b[32m   2358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_sets[-\u001b[32m1\u001b[39m].num_row() == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/MLE_Nequi/.venv/lib/python3.12/site-packages/catboost/core.py:769\u001b[39m, in \u001b[36mPool.__init__\u001b[39m\u001b[34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, graph, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr, data_can_be_none)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    768\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_data_type(data)\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_data_empty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    770\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pairs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, PATH_TYPES) != \u001b[38;5;28misinstance\u001b[39m(pairs, PATH_TYPES):\n\u001b[32m    771\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[33m\"\u001b[39m\u001b[33mdata and pairs parameters should be the same types.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/MLE_Nequi/.venv/lib/python3.12/site-packages/catboost/core.py:945\u001b[39m, in \u001b[36mPool._check_data_empty\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    943\u001b[39m     data_shape = np.shape(data)\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_shape) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m data_shape[\u001b[32m0\u001b[39m] > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, Iterable):\n\u001b[32m    946\u001b[39m         data_shape = \u001b[38;5;28mtuple\u001b[39m(data_shape + \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mlen\u001b[39m(data[\u001b[32m0\u001b[39m])]))\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/MLE_Nequi/.venv/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/MLE_Nequi/.venv/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1236\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/proyectos/MLE_Nequi/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "# Implementar el flujo MLOps completo\n",
    "try:\n",
    "    with mlflow.start_run(run_name=f'reentrenamiento_{datetime.now().strftime('%Y%m%d_%H%M')}') as run:\n",
    "        log_info('=== INICIANDO PROCESO DE REENTRENAMIENTO MLOPS ===')\n",
    "            \n",
    "        # 1. Obtener modelo campe贸n\n",
    "        log_info('1. Obteniendo modelo campe贸n...')\n",
    "        champion_model, champion_run_id = get_champion_model()\n",
    "            \n",
    "        if champion_model is not None:\n",
    "            log_info('Modelo campe贸n cargado correctamente')\n",
    "            # Registrar informaci贸n del modelo campe贸n\n",
    "            mlflow.set_tag('champion_run_id', champion_run_id)\n",
    "        else:\n",
    "            log_info('No se encontr贸 modelo campe贸n existente')\n",
    "            \n",
    "        # 2. Optimizar hiperpar谩metros (si hay suficientes datos)\n",
    "        if len(X_train) > 1000:  # Solo optimizar si hay suficientes datos\n",
    "            log_info('2. Optimizando hiperpar谩metros para modelo desafiante...')\n",
    "            best_params = optimize_hyperparameters(X_train, y_train, X_valid, y_valid, max_evals=10)\n",
    "        else:\n",
    "            log_info('No hay suficientes datos para optimizaci贸n de hiperpar谩metros, usando valores por defecto')\n",
    "            best_params = {\n",
    "                'iterations': 500,\n",
    "                'depth': 6,\n",
    "                'learning_rate': 0.1,\n",
    "                'verbose': 100,\n",
    "                'max_features': 100\n",
    "            }\n",
    "            \n",
    "        # Registrar hiperpar谩metros\n",
    "        for param_name, param_value in best_params.items():\n",
    "            mlflow.log_param(param_name, param_value)\n",
    "            \n",
    "        # 3. Entrenar modelo desafiante\n",
    "        log_info('3. Entrenando modelo desafiante...')\n",
    "        challenger_model = train_challenger_model(X_train, y_train, X_valid, y_valid, best_params)\n",
    "            \n",
    "        # 4. Evaluar ambos modelos en conjunto de prueba\n",
    "        log_info('4. Evaluando modelos en conjunto de prueba...')\n",
    "            \n",
    "        if champion_model is not None:\n",
    "            champion_metrics, champion_report = evaluate_model(champion_model, X_test, y_test, 'Modelo Campe贸n')\n",
    "            # Guardar matriz de confusi贸n y curva ROC\n",
    "            cm_fig_champion = plot_confusion_matrix(champion_model, X_test, y_test, 'Matriz de Confusi贸n - Modelo Campe贸n')\n",
    "            if cm_fig_champion:\n",
    "                mlflow.log_figure(cm_fig_champion, 'confusion_matrix_champion.png')\n",
    "                    \n",
    "            roc_fig_champion = plot_roc_curve(champion_model, X_test, y_test, 'Modelo Campe贸n')\n",
    "            if roc_fig_champion:\n",
    "                mlflow.log_figure(roc_fig_champion, 'roc_curve_champion.png')\n",
    "        else:\n",
    "            champion_metrics = None\n",
    "            champion_report = None\n",
    "            \n",
    "        challenger_metrics, challenger_report = evaluate_model(challenger_model, X_test, y_test, 'Modelo Desafiante')\n",
    "            \n",
    "        # Guardar matriz de confusi贸n y curva ROC\n",
    "        cm_fig_challenger = plot_confusion_matrix(challenger_model, X_test, y_test, 'Matriz de Confusi贸n - Modelo Desafiante')\n",
    "        if cm_fig_challenger:\n",
    "            mlflow.log_figure(cm_fig_challenger, 'confusion_matrix_challenger.png')\n",
    "                \n",
    "        roc_fig_challenger = plot_roc_curve(challenger_model, X_test, y_test, 'Modelo Desafiante')\n",
    "        if roc_fig_challenger:\n",
    "            mlflow.log_figure(roc_fig_challenger, 'roc_curve_challenger.png')\n",
    "            \n",
    "        # 5. Comparar modelos\n",
    "        log_info('5. Comparando modelos...')\n",
    "        is_challenger_better, all_metrics_comparison, primary_comparison = compare_models(\n",
    "            champion_metrics, challenger_metrics, PRIMARY_METRIC, IMPROVEMENT_THRESHOLD\n",
    "        )\n",
    "            \n",
    "        # Guardar comparaciones\n",
    "        mlflow.log_dict(all_metrics_comparison, 'metrics_comparison.json')\n",
    "        mlflow.log_dict(primary_comparison, f'{PRIMARY_METRIC}_comparison.json')\n",
    "            \n",
    "        # 6. Registrar modelo ganador\n",
    "        if is_challenger_better:\n",
    "            log_info('6. El modelo desafiante es mejor. Promoviendo a nuevo campe贸n...')\n",
    "            register_challenger_model(challenger_model, challenger_metrics, X_train, y_train, is_champion=True)\n",
    "            mlflow.log_param('winner', 'challenger')\n",
    "        else:\n",
    "            log_info('6. El modelo campe贸n sigue siendo mejor. Registrando desafiante para referencia...')\n",
    "            register_challenger_model(challenger_model, challenger_metrics, X_train, y_train, is_champion=False)\n",
    "            mlflow.log_param('winner', 'champion')\n",
    "            \n",
    "        log_info('=== PROCESO MLOps COMPLETADO EXITOSAMENTE ===')\n",
    "except Exception as e:\n",
    "    log_error(f'Error en flujo MLOps: {e}')\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d3da79",
   "metadata": {},
   "source": [
    "## Visualizaciones de Resultados\n",
    "    \n",
    "A continuaci贸n, se muestran algunas visualizaciones adicionales para analizar y comparar los modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4753300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_comparison(champion_metrics, challenger_metrics):\n",
    "    '''Genera gr谩ficos comparativos de m茅tricas entre el modelo campe贸n y el desafiante.'''\n",
    "    try:\n",
    "        if champion_metrics is None:\n",
    "            log_info('No hay m茅tricas del modelo campe贸n para comparar.')\n",
    "            return None\n",
    "                \n",
    "        # Encontrar m茅tricas comunes\n",
    "        common_metrics = set(champion_metrics.keys()).intersection(set(challenger_metrics.keys()))\n",
    "            \n",
    "        # Preparar datos para ploteo\n",
    "        metrics_names = list(common_metrics)\n",
    "        champion_values = [champion_metrics[metric] for metric in metrics_names]\n",
    "        challenger_values = [challenger_metrics[metric] for metric in metrics_names]\n",
    "            \n",
    "        # Crear figura\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            \n",
    "        # Configuraci贸n de barras\n",
    "        x = np.arange(len(metrics_names))\n",
    "        width = 0.35\n",
    "            \n",
    "        # Graficar barras\n",
    "        ax.bar(x - width/2, champion_values, width, label='Modelo Campe贸n')\n",
    "        ax.bar(x + width/2, challenger_values, width, label='Modelo Desafiante')\n",
    "            \n",
    "        # A帽adir etiquetas y t铆tulo\n",
    "        ax.set_xlabel('M茅tricas')\n",
    "        ax.set_ylabel('Valor')\n",
    "        ax.set_title('Comparaci贸n de M茅tricas entre Modelos')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(metrics_names)\n",
    "        ax.legend()\n",
    "            \n",
    "        # A帽adir valores encima de cada barra\n",
    "        for i, v in enumerate(champion_values):\n",
    "            ax.text(i - width/2, v + 0.01, f'{v:.3f}', ha='center')\n",
    "                \n",
    "        for i, v in enumerate(challenger_values):\n",
    "            ax.text(i + width/2, v + 0.01, f'{v:.3f}', ha='center')\n",
    "                \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    except Exception as e:\n",
    "        log_error(f'Error al generar gr谩fico comparativo: {e}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparaci贸n de m茅tricas si hay dos modelos para comparar\n",
    "if champion_metrics is not None and challenger_metrics is not None:\n",
    "    comparison_fig = plot_metrics_comparison(champion_metrics, challenger_metrics)\n",
    "    if comparison_fig:\n",
    "        # Mostrar en notebook\n",
    "        plt.show()\n",
    "        # Guardar en MLflow\n",
    "        with mlflow.start_run(run_id=run.info.run_id):\n",
    "            mlflow.log_figure(comparison_fig, 'metrics_comparison.png')\n",
    "else:\n",
    "    print('No hay dos modelos para comparar m茅tricas.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee390e2",
   "metadata": {},
   "source": [
    "## Automatizaci贸n del Proceso MLOps\n",
    "    \n",
    "Para integrar este notebook en un flujo de trabajo automatizado MLOps, se puede exportar como script Python y programar su ejecuci贸n peri贸dica usando herramientas como Apache Airflow, cron jobs, o plataformas CI/CD. A continuaci贸n se muestra c贸mo configurar los metadatos del experimento para facilitar el seguimiento.\n",
    "    \n",
    "Ejemplo de configuraci贸n para Airflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este c贸digo no se ejecuta aqu铆, es solo un ejemplo de DAG para Airflow\n",
    "'''\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "    \n",
    "default_args = {\n",
    "    'owner': 'mlops',\n",
    "    'depends_on_past': False,\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "    \n",
    "def run_retraining():\n",
    "    # Ejecutar script de reentrenamiento\n",
    "    subprocess.run(['python', 'reentrenamiento_mlops.py'])\n",
    "    \n",
    "with DAG(\n",
    "    'modelo_catboost_retraining',\n",
    "    default_args=default_args,\n",
    "    description='Reentrenamiento peri贸dico del modelo de clasificaci贸n',\n",
    "    schedule_interval=timedelta(days=7),  # Reentrenar semanalmente\n",
    "    start_date=datetime(2025, 5, 1),\n",
    "    catchup=False,\n",
    ") as dag:\n",
    "    retraining_task = PythonOperator(\n",
    "        task_id='reentrenamiento_modelo',\n",
    "        python_callable=run_retraining,\n",
    "    )\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff3189",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "    \n",
    "Este notebook implementa un flujo MLOps completo para:\n",
    "    \n",
    "1. **Entrenamiento automatizado**: Entrenamiento automatizado del modelo utilizando los 煤ltimos datos disponibles.\n",
    "2. **Optimizaci贸n de hiperpar谩metros**: B煤squeda autom谩tica de los mejores hiperpar谩metros para el modelo.\n",
    "3. **Gesti贸n de modelos**: Uso de MLflow para registrar y versionar modelos.\n",
    "4. **Evaluaci贸n comparativa**: Comparaci贸n sistem谩tica entre modelo campe贸n y desafiante.\n",
    "5. **Promoci贸n autom谩tica**: Promoci贸n autom谩tica del mejor modelo a producci贸n basado en m茅tricas objetivas.\n",
    "    \n",
    "Este enfoque garantiza que solo los modelos que realmente mejoran el rendimiento sean promovidos a producci贸n, manteniendo un historial completo de experimentos y decisiones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C贸digo para exportar este notebook como script Python (opcional)\n",
    "try:\n",
    "    !jupyter nbconvert --to python reentrenamiento_mlops.ipynb\n",
    "    print('Notebook exportado como script Python: reentrenamiento_mlops.py')\n",
    "except Exception as e:\n",
    "    print(f'Error al exportar notebook: {e}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
