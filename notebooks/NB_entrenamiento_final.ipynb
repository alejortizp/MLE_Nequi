{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f19d67",
   "metadata": {},
   "source": [
    "## Script de entrenamiento y re-entrenamiento de modelos con prácticas MLOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d03916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar variables de entorno\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from catboost import CatBoostClassifier\n",
    "import time\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score, f1_score, fbeta_score, roc_curve, average_precision_score\n",
    "\n",
    "# Importar funciones desde nuestro módulo de funciones\n",
    "from NB_funciones import (\n",
    "    CargarDatos,\n",
    "    log_info, \n",
    "    log_error,\n",
    "    setup_environment,\n",
    "    preprocess_data,\n",
    "    create_mlflow_experiment,\n",
    "    evaluate_model,\n",
    "    run_model_training_pipeline,\n",
    "    data_drift_detection,\n",
    "    model_performance_monitoring\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1eb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del logging\n",
    "logging.basicConfig(\n",
    "    filename=\"errores_entrenamiento.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f67aa495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración sin tracking_uri\n",
    "CONFIG = {\n",
    "    \"data\": {\n",
    "        \"dataset_name\": \"customer_support_twitter_twcs\",\n",
    "        \"text_column\": \"text\",\n",
    "        \"target_column\": \"inbound\",\n",
    "        \"test_size\": 0.3,\n",
    "        \"valid_size\": 0.3,\n",
    "        \"random_state\": 42\n",
    "    },\n",
    "    \"mlflow\": {\n",
    "        \"experiment_name\": \"experimento_nuevo_final\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"name\": \"modelo_nuevo\",\n",
    "        \"version\": \"1.0.1\",\n",
    "        \"champion_threshold\": 0.5,\n",
    "        \"parameters\": {\n",
    "            \"iterations\": 50,\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"depth\": 6,\n",
    "            \"l2_leaf_reg\": 3,\n",
    "            \"random_seed\": 42\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f952e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mlflow():\n",
    "    \"\"\"\n",
    "    Configura MLflow obteniendo o creando un experimento según su nombre.\n",
    "\n",
    "    La función intenta recuperar un experimento existente en MLflow por su nombre.\n",
    "    Si el experimento no existe, se crea uno nuevo. En caso de error en la conexión con MLflow, \n",
    "    se implementa una espera (`sleep`) antes de retornar `None`.\n",
    "\n",
    "    Args:\n",
    "        None (usa la configuración global `CONFIG` para obtener el nombre del experimento).\n",
    "\n",
    "    Returns:\n",
    "        str | None: Identificador del experimento (`experiment_id`) si la configuración es exitosa, \n",
    "                    `None` en caso de fallo.\n",
    "\n",
    "    Raises:\n",
    "        mlflow.exceptions.MlflowException: Maneja errores de conexión con MLflow y los registra en los logs.\n",
    "    \"\"\"\n",
    "    experiment_name = CONFIG[\"mlflow\"][\"experiment_name\"]\n",
    "    \n",
    "    try:\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        \n",
    "        if experiment is None:\n",
    "            log_info(f\"Creando nuevo experimento: {experiment_name}\")\n",
    "            experiment_id = mlflow.create_experiment(experiment_name)\n",
    "        else:\n",
    "            experiment_id = experiment.experiment_id\n",
    "        \n",
    "        return experiment_id\n",
    "    \n",
    "    except mlflow.exceptions.MlflowException as e:\n",
    "        log_error(f\"Error al conectar con MLflow: {e}\")\n",
    "        time.sleep(5)\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Ejecuta el pipeline completo de entrenamiento, minimizando conexiones innecesarias con MLflow.\n",
    "\n",
    "    Este pipeline configura el entorno, carga y preprocesa datos, define parámetros del modelo,\n",
    "    construye un pipeline de entrenamiento y maneja la comparación con un modelo campeón si existe.\n",
    "    También registra el modelo en MLflow con sus métricas y artefactos relevantes.\n",
    "\n",
    "    Returns:\n",
    "        None: La función ejecuta el flujo completo sin retorno explícito.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Captura errores en distintas etapas y los registra en los logs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        log_info(\"Iniciando pipeline de entrenamiento...\")\n",
    "        setup_environment()\n",
    "\n",
    "        # Configurar MLflow con una sola conexión inicial\n",
    "        experiment_id = setup_mlflow()\n",
    "        if experiment_id is None:\n",
    "            log_error(\"No se pudo establecer conexión con MLflow. Deteniendo ejecución.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Cargar datos\n",
    "            ruta = CargarDatos(CONFIG[\"data\"][\"dataset_name\"])\n",
    "            data = ruta.cargar_csv()\n",
    "            log_info(f\"Dataset cargado con {data.shape[0]} registros.\")\n",
    "            logging.info(f\"Dataset cargado con {data.shape[0]} registros.\")\n",
    "        except Exception as e:\n",
    "            log_error(f\"Error al cargar el dataset: {e}\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Preprocesar datos\n",
    "            text_column = CONFIG[\"data\"][\"text_column\"]\n",
    "            target_column = CONFIG[\"data\"][\"target_column\"]\n",
    "            data_splits = preprocess_data(data, text_column, target_column)\n",
    "            logging.info(f\"Datos preprocesados: {data_splits['X_train'].shape[0]} train, {data_splits['X_test'].shape[0]} test.\")\n",
    "        except Exception as e:\n",
    "            log_error(f\"Error en la preprocesación de datos: {e}\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Definir parámetros\n",
    "            english_stopwords = stopwords.words('english')\n",
    "            catboost_params = CONFIG[\"model\"][\"parameters\"]\n",
    "            logging.info(f\"Parámetros de CatBoost: {catboost_params}\")\n",
    "        except Exception as e:\n",
    "            log_error(f\"Error al definir parámetros: {e}\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Construir pipeline\n",
    "            pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=english_stopwords, max_features=100, lowercase=True, token_pattern=r'\\b\\w+\\b')),\n",
    "                ('catboost', CatBoostClassifier(**catboost_params))\n",
    "            ])\n",
    "            logging.info(\"Pipeline construido exitosamente.\")\n",
    "        except Exception as e:\n",
    "            log_error(f\"Error al construir el pipeline: {e}\")\n",
    "            return\n",
    "\n",
    "        # Verificar si hay modelo campeón\n",
    "        try:\n",
    "            from NB_funciones import get_champion_model, compare_models\n",
    "            champion_model, _ = get_champion_model(model_name=CONFIG[\"model\"][\"name\"])\n",
    "        except mlflow.exceptions.MlflowException:\n",
    "            log_error(\"Fallo en la conexión con MLflow mientras obtenía el modelo campeón.\")\n",
    "            return\n",
    "\n",
    "        ''' \n",
    "        try:\n",
    "            # Solo entrenar si es necesario\n",
    "            if not champion_model:\n",
    "                log_info(\"No hay modelo campeón, por lo que no se realizará comparación.\")\n",
    "                return\n",
    "\n",
    "            champion_metrics = evaluate_model(champion_model, data_splits[\"X_test\"], data_splits[\"y_test\"])\n",
    "            \n",
    "            temp_model = pipeline  # Usa el pipeline en lugar del modelo directamente\n",
    "            temp_model.fit(data_splits[\"X_train\"][text_column], data_splits[\"y_train\"])\n",
    "\n",
    "            # Evaluar challenger solo si hay un modelo campeón\n",
    "            challenger_metrics = evaluate_model(temp_model, data_splits[\"X_test\"][text_column], data_splits[\"y_test\"])\n",
    "\n",
    "            is_better, all_metrics, comparison = compare_models(champion_metrics, challenger_metrics, \"accuracy\", CONFIG[\"model\"][\"champion_threshold\"])\n",
    "\n",
    "            if not is_better:\n",
    "                log_info(\"El modelo retador no supera al campeón, terminando ejecución.\")\n",
    "                return\n",
    "\n",
    "            log_info(\"El modelo retador supera al campeón, continuando con el entrenamiento.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            log_error(f\"Error al comparar modelos: {e}\")\n",
    "            return\n",
    "\n",
    "        '''\n",
    "        \n",
    "        try:\n",
    "        # Registrar modelo solo si supera al campeón\n",
    "            with mlflow.start_run(experiment_id=experiment_id):\n",
    "                \n",
    "                try:\n",
    "                    # Inferir signature para input/output\n",
    "                    signature = infer_signature(data_splits[\"X_train\"], data_splits[\"y_train\"])\n",
    "                    log_info(f\"Signature inferida: {signature.inputs}, {signature.outputs}\")\n",
    "                except Exception as e:\n",
    "                    log_error(f\"Error al inferir signature: {e}\")\n",
    "                    return\n",
    "                \n",
    "\n",
    "                \n",
    "                try:\n",
    "                    # Registra el modelo con un ejemplo de entrada\n",
    "                    input_example = np.array(data_splits[\"X_train\"][:1])  # Toma una muestra como ejemplo de entrada\n",
    "                    log_info(f\"Ejemplo de entrada: {input_example}\")\n",
    "                except Exception as e:\n",
    "                    log_error(f\"Error al registrar el ejemplo de entrada: {e}\")\n",
    "                    return\n",
    "                \n",
    "\n",
    "                try:\n",
    "                    model = pipeline  # Usa el pipeline en lugar del modelo directamente\n",
    "                    model.fit(data_splits[\"X_train\"], data_splits[\"y_train\"]) \n",
    "                    mlflow.sklearn.log_model(model, CONFIG[\"model\"][\"name\"], signature=signature, input_example=input_example) # signature=signature, input_example=input_example\n",
    "                    log_info(f\"Modelo registrado: {CONFIG['model']['name']}\")\n",
    "                except Exception as e:\n",
    "                    log_error(f\"Error al registrar el modelo: {e}\")\n",
    "                    return\n",
    "\n",
    "                try:\n",
    "                    # Registra las métricas\n",
    "                    accuracy = pipeline.score(data_splits[\"X_test\"], data_splits[\"y_test\"])\n",
    "                    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "                    # Registra los hiperparámetros del modelo\n",
    "                    mlflow.log_params(catboost_params)\n",
    "                    log_info(f\"Parámetros registrados: {catboost_params}\")\n",
    "                except Exception as e:\n",
    "                    log_error(f\"Error al registrar las métricas y parámetros: {e}\")\n",
    "                    return\n",
    "                \n",
    "                log_info(f\"Modelo registrado con ID: {mlflow.active_run().info.run_id}\")\n",
    "                logging.info(f\"Modelo registrado con ID: {mlflow.active_run().info.run_id}\")\n",
    "        except Exception as e:\n",
    "            log_error(f\"Error al registrar el modelo: {e}\")\n",
    "            return\n",
    "            \n",
    "        log_info(\"Pipeline completado exitosamente.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_error(f\"Error crítico en el pipeline: {e}\")\n",
    "        raise e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0df8c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iniciando pipeline de entrenamiento...\n",
      "INFO:root:Recursos NLTK descargados correctamente\n",
      "INFO:root:Archivo /home/alejo/proyectos/MLE_Nequi/datasets/Customer_Support_Twitter/twcs/twcs.csv cargado correctamente.\n",
      "INFO:root:Dataset cargado con 2811774 registros.\n",
      "INFO:root:Dataset cargado con 2811774 registros.\n",
      "INFO:root:Datos divididos: Train 1377768, Valid 590473, Test 843533 registros\n",
      "INFO:root:Datos preprocesados: 1377768 train, 843533 test.\n",
      "INFO:root:Parámetros de CatBoost: {'iterations': 50, 'learning_rate': 0.05, 'depth': 6, 'l2_leaf_reg': 3, 'random_seed': 42}\n",
      "INFO:root:Pipeline construido exitosamente.\n",
      "INFO:root:No se encontró un modelo modelo_nuevo en producción. Buscando en staging...\n",
      "INFO:root:No se encontró un modelo modelo_nuevo en staging. Buscando la versión más reciente...\n",
      "INFO:root:Modelo campeón cargado: modelo_nuevo version 1\n",
      "INFO:root:Signature inferida: ['text': string (required)], ['inbound': long (required)]\n",
      "INFO:root:Ejemplo de entrada: ['@697893 We recommend restarting into Safe Mode, which could help resolve this issue. Once you exit safe mode, please shut down again to test everything and see if the same error occurs. https://t.co/PQ4LSYhUTY']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6598960\ttotal: 317ms\tremaining: 15.5s\n",
      "1:\tlearn: 0.6370777\ttotal: 491ms\tremaining: 11.8s\n",
      "2:\tlearn: 0.6168338\ttotal: 674ms\tremaining: 10.6s\n",
      "3:\tlearn: 0.5958284\ttotal: 833ms\tremaining: 9.58s\n",
      "4:\tlearn: 0.5806152\ttotal: 1.07s\tremaining: 9.66s\n",
      "5:\tlearn: 0.5639175\ttotal: 1.22s\tremaining: 8.98s\n",
      "6:\tlearn: 0.5526613\ttotal: 1.39s\tremaining: 8.51s\n",
      "7:\tlearn: 0.5440200\ttotal: 1.54s\tremaining: 8.09s\n",
      "8:\tlearn: 0.5342910\ttotal: 1.7s\tremaining: 7.76s\n",
      "9:\tlearn: 0.5259656\ttotal: 1.85s\tremaining: 7.4s\n",
      "10:\tlearn: 0.5170124\ttotal: 2.02s\tremaining: 7.17s\n",
      "11:\tlearn: 0.5116431\ttotal: 2.18s\tremaining: 6.89s\n",
      "12:\tlearn: 0.5070783\ttotal: 2.35s\tremaining: 6.68s\n",
      "13:\tlearn: 0.4995751\ttotal: 2.5s\tremaining: 6.42s\n",
      "14:\tlearn: 0.4956645\ttotal: 2.67s\tremaining: 6.24s\n",
      "15:\tlearn: 0.4918052\ttotal: 2.83s\tremaining: 6s\n",
      "16:\tlearn: 0.4883282\ttotal: 2.99s\tremaining: 5.81s\n",
      "17:\tlearn: 0.4850928\ttotal: 3.15s\tremaining: 5.6s\n",
      "18:\tlearn: 0.4792147\ttotal: 3.31s\tremaining: 5.41s\n",
      "19:\tlearn: 0.4746092\ttotal: 3.48s\tremaining: 5.21s\n",
      "20:\tlearn: 0.4720899\ttotal: 3.65s\tremaining: 5.04s\n",
      "21:\tlearn: 0.4698576\ttotal: 3.8s\tremaining: 4.83s\n",
      "22:\tlearn: 0.4676378\ttotal: 3.98s\tremaining: 4.67s\n",
      "23:\tlearn: 0.4626021\ttotal: 4.12s\tremaining: 4.46s\n",
      "24:\tlearn: 0.4605144\ttotal: 4.29s\tremaining: 4.29s\n",
      "25:\tlearn: 0.4586428\ttotal: 4.44s\tremaining: 4.09s\n",
      "26:\tlearn: 0.4566908\ttotal: 4.6s\tremaining: 3.92s\n",
      "27:\tlearn: 0.4537859\ttotal: 4.76s\tremaining: 3.74s\n",
      "28:\tlearn: 0.4519774\ttotal: 4.93s\tremaining: 3.57s\n",
      "29:\tlearn: 0.4504157\ttotal: 5.22s\tremaining: 3.48s\n",
      "30:\tlearn: 0.4479740\ttotal: 5.41s\tremaining: 3.32s\n",
      "31:\tlearn: 0.4466001\ttotal: 5.58s\tremaining: 3.14s\n",
      "32:\tlearn: 0.4451396\ttotal: 5.74s\tremaining: 2.95s\n",
      "33:\tlearn: 0.4409304\ttotal: 5.89s\tremaining: 2.77s\n",
      "34:\tlearn: 0.4391525\ttotal: 6.07s\tremaining: 2.6s\n",
      "35:\tlearn: 0.4377865\ttotal: 6.26s\tremaining: 2.43s\n",
      "36:\tlearn: 0.4365083\ttotal: 6.44s\tremaining: 2.26s\n",
      "37:\tlearn: 0.4353646\ttotal: 6.63s\tremaining: 2.09s\n",
      "38:\tlearn: 0.4336237\ttotal: 6.8s\tremaining: 1.92s\n",
      "39:\tlearn: 0.4324004\ttotal: 7s\tremaining: 1.75s\n",
      "40:\tlearn: 0.4313081\ttotal: 7.17s\tremaining: 1.57s\n",
      "41:\tlearn: 0.4304244\ttotal: 7.34s\tremaining: 1.4s\n",
      "42:\tlearn: 0.4294486\ttotal: 7.5s\tremaining: 1.22s\n",
      "43:\tlearn: 0.4283168\ttotal: 7.66s\tremaining: 1.04s\n",
      "44:\tlearn: 0.4270498\ttotal: 7.8s\tremaining: 867ms\n",
      "45:\tlearn: 0.4260409\ttotal: 7.96s\tremaining: 692ms\n",
      "46:\tlearn: 0.4238461\ttotal: 8.12s\tremaining: 518ms\n",
      "47:\tlearn: 0.4229173\ttotal: 8.28s\tremaining: 345ms\n",
      "48:\tlearn: 0.4211951\ttotal: 8.42s\tremaining: 172ms\n",
      "49:\tlearn: 0.4204972\ttotal: 8.59s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Modelo registrado: modelo_nuevo\n",
      "INFO:root:Parámetros registrados: {'iterations': 50, 'learning_rate': 0.05, 'depth': 6, 'l2_leaf_reg': 3, 'random_seed': 42}\n",
      "INFO:root:Modelo registrado con ID: 2f7f3f9f11b84f4dae328a7353a5d1b2\n",
      "INFO:root:Modelo registrado con ID: 2f7f3f9f11b84f4dae328a7353a5d1b2\n",
      "INFO:root:Pipeline completado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de0b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook NB_entrenamiento_final.ipynb to script\n",
      "[NbConvertApp] Writing 10143 bytes to NB_entrenamiento_final.py\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbconvert --to script NB_entrenamiento_final.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
