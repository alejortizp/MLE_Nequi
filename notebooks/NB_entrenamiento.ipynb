{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "382f02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import unicodedata\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score, f1_score, fbeta_score, roc_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import string \n",
    "import joblib\n",
    "import warnings\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d76677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del logging\n",
    "logging.basicConfig(\n",
    "    filename=\"errores_entrenamiento.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5168c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "try:\n",
    "    load_dotenv()\n",
    "    ruta_cst_twcs = os.getenv(\"customer_support_twitter_twcs\")\n",
    "    logging.info(\"Environment variables loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading environment variables: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3be8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2811774, 7)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "try:\n",
    "    data_cst_twcs = pd.read_csv(ruta_cst_twcs)\n",
    "    print(data_cst_twcs.shape)\n",
    "    logging.info(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    logging.error(f\"File not found: {ruta_cst_twcs}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa21873d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cst_twcs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70c6039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the 'inbound' column to int\n",
    "try:\n",
    "    data_cst_twcs['inbound'] = data_cst_twcs['inbound'].astype('int')\n",
    "    logging.info(\"Data transformed successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error transforming data: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a3659f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alejo/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/alejo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# load stopwords\n",
    "try:\n",
    "    nltk.download('punkt')\n",
    "    #nltk.download('wordnet')\n",
    "    nltk.download('stopwords')\n",
    "    english_stopwords = stopwords.words('english')\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading stopwords: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "385c27c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1377768,)\n",
      "X_valid:  (590473,)\n",
      "X_test:  (843533,)\n",
      "y_train:  (1377768,)\n",
      "y_valid:  (590473,)\n",
      "y_test:  (843533,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into train, validation and test sets\n",
    "# stratified split to maintain the same proportion of classes in each set\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_cst_twcs['text'], data_cst_twcs['inbound'], test_size=0.3, stratify=data_cst_twcs['inbound'], random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=42)\n",
    "    print('X_train: ', X_train.shape)\n",
    "    print('X_valid: ', X_valid.shape)\n",
    "    print('X_test: ', X_test.shape)\n",
    "    print('y_train: ', y_train.shape)\n",
    "    print('y_valid: ', y_valid.shape)\n",
    "    print('y_test: ', y_test.shape)\n",
    "    logging.info(\"Data split into train, validation and test sets successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error splitting data: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2efb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizar el texto con TF-IDF\n",
    "#vectorizer = TfidfVectorizer(stop_words=english_stopwords, max_features=100, lowercase=True, token_pattern=r'\\b\\w+\\b')\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the train, validation and test sets\n",
    "#X_train = vectorizer.fit_transform(X_train)\n",
    "#X_valid = vectorizer.transform(X_valid)\n",
    "#X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f83ea524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento creado\n"
     ]
    }
   ],
   "source": [
    "# Set the experiment name\n",
    "try:\n",
    "    mlflow.create_experiment(\"experimento_catboost\")\n",
    "    print(\"Experimento creado\")\n",
    "    logging.info(\"Experiment created successfully.\")\n",
    "except:\n",
    "    mlflow.set_experiment(\"experimento_catboost\")\n",
    "    print(\"Experimento ya existe\")\n",
    "    logging.info(\"Experiment already exists, set to existing experiment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b47d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando el experimento...\n",
      "0:\tlearn: 0.6316539\ttotal: 265ms\tremaining: 2m 12s\n",
      "100:\tlearn: 0.3638261\ttotal: 16.2s\tremaining: 1m 3s\n",
      "200:\tlearn: 0.3455131\ttotal: 31s\tremaining: 46.1s\n",
      "300:\tlearn: 0.3375544\ttotal: 45.4s\tremaining: 30s\n",
      "400:\tlearn: 0.3330456\ttotal: 1m\tremaining: 14.8s\n",
      "499:\tlearn: 0.3297846\ttotal: 1m 19s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'modelo_catboost_prueba' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'modelo_catboost_prueba'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo registrado con precisión: 0.8513466574514571\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Iniciando el experimento...\")\n",
    "    with mlflow.start_run():\n",
    "        # Define y entrena el pipeline\n",
    "        catboost_params = {\n",
    "            \"iterations\": 500,\n",
    "            \"depth\": 6,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"verbose\": 100\n",
    "        }\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words=english_stopwords, max_features=100, lowercase=True, token_pattern=r'\\b\\w+\\b')),\n",
    "            ('catboost', CatBoostClassifier(**catboost_params))\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Inferir signature para input/output\n",
    "        signature = infer_signature(X_train, y_train)\n",
    "\n",
    "        # Registra el modelo con un ejemplo de entrada\n",
    "        input_example = np.array(X_train[:1])  # Toma una muestra como ejemplo de entrada\n",
    "        mlflow.sklearn.log_model(pipeline, \"modelo_catboost\", input_example=input_example, signature=signature, registered_model_name=\"modelo_catboost_prueba\")\n",
    "\n",
    "        # Registra las métricas\n",
    "        accuracy = pipeline.score(X_test, y_test)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Registra los hiperparámetros del modelo\n",
    "        mlflow.log_params(catboost_params)\n",
    "\n",
    "        print(f\"Modelo registrado con precisión: {accuracy}\")\n",
    "        logging.info(f\"Modelo registrado con precisión: {accuracy}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during MLflow run: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5f8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
